{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "aeb6648b-9307-4a16-a7ae-1572defd0903",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import lyricsgenius\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac65653c-254e-4821-950d-e4a4ff73f341",
   "metadata": {},
   "source": [
    "To get the lyrics of the songs we are going to use the `lyricgenius` library. This library requires a Genius API key which can be generated creating a free account in [Genius](https://genius.com)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e652edb5-d021-4cda-9348-39644d8e1f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load enviroment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# acces the variable\n",
    "token = os.getenv(\"GENIUS_API_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f205f8-4e19-4e4f-bc4d-f08b3d8d7737",
   "metadata": {},
   "source": [
    "Now we create the genius object that we will use to fetch the songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d211f8f9-f4e2-4e77-9781-add0bd72ad58",
   "metadata": {},
   "outputs": [],
   "source": [
    "genius = lyricsgenius.Genius(token)\n",
    "genius.remove_section_headers = True \n",
    "genius.verbose = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b71f82-0afe-42d6-989a-8638b35fb12e",
   "metadata": {},
   "source": [
    "To find the songs of a given artist we need its `id`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0b3db78-acdd-4753-b493-fa063c3cc011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{27132: 'Kase.O', 55782: 'SFDK', 1556128: 'Ayax y Prok', 1062440: 'Kaze'}\n"
     ]
    }
   ],
   "source": [
    "artist_names = [\"Kase.O\", \"SFDK\", \"Ayax y Prok\", \"Kaze\"]\n",
    "\n",
    "artists = {}\n",
    "\n",
    "for name in artist_names:\n",
    "    artist_id = genius.search_artist(name, max_songs=0).id\n",
    "    artists[artist_id] = name\n",
    "\n",
    "print(artists)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0baa8b3d-3ee3-4504-bc64-b7bcc27d3548",
   "metadata": {},
   "source": [
    "Now we can go through the pages of the website to find songs of our artist. We will omit colaborations, live songs and remixes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd7444e9-b505-426d-92e5-ed671a17ddf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_songs(artist_id, page):  \n",
    "    songs = genius.artist_songs(artist_id, page=3)[\"songs\"]\n",
    "    \n",
    "    songs = list(filter(lambda x: len(x[\"featured_artists\"]) == 0, songs))\n",
    "    songs = list(filter(lambda x: x[\"artist_names\"] == artists[artist_id], songs))\n",
    "    \n",
    "    omit_words = [\"Directo\", \"Remix\", \"Mix\"]\n",
    "    pattern = '|'.join(map(re.escape, omit_words))\n",
    "    \n",
    "    songs = list(filter(lambda x: not re.search(pattern, x[\"full_title\"], re.IGNORECASE), songs))\n",
    "    \n",
    "    song_ids = [song[\"id\"] for song in songs]\n",
    "    \n",
    "    return song_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59508b94-2ec0-40d3-8ede-c5fbd256937d",
   "metadata": {},
   "source": [
    "We will keep fetching songs until we have 10k words per artist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6580c170-07ae-475a-9838-3b922f465cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished downloading Kase.O words: 10955, songs: 8 songs, 3 pages\n",
      "Finished downloading SFDK words: 10058, songs: 9 songs, 2 pages\n",
      "Finished downloading Ayax y Prok words: 10100, songs: 11 songs, 3 pages\n",
      "Finished downloading Kaze words: 10503, songs: 9 songs, 3 pages\n"
     ]
    }
   ],
   "source": [
    "texts = {}\n",
    "\n",
    "MINIMUM_WORDS = 10000\n",
    "\n",
    "for artist_id, artist_name in artists.items():\n",
    "    wordcount = 0\n",
    "    songcount = 0\n",
    "    done = False\n",
    "    page = 1\n",
    "    texts[artist_name] = \"\"\n",
    "    \n",
    "    while not done:\n",
    "        for song_id in find_songs(artist_id, page):\n",
    "            song = genius.search_song(song_id=song_id)\n",
    "\n",
    "            if song:\n",
    "                text = song.to_text()\n",
    "                texts[artist_name] += text\n",
    "\n",
    "                wordcount += len(text.split())\n",
    "                songcount += 1\n",
    "            \n",
    "                if wordcount > MINIMUM_WORDS:\n",
    "                    done = True\n",
    "                    break\n",
    "    \n",
    "        page +=1 \n",
    "\n",
    "    print(f\"Finished downloading {artist_name} words: {wordcount}, songs: {songcount} songs, {page} pages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af6a0fe-104f-46ea-83aa-e6f511909de8",
   "metadata": {},
   "source": [
    "Now we have one text for each artist. However, we as we can see there are some errors like `\"2 ContributorsDe Una; Pt. 2: Ya No Puedo Más Lyrics\"` or `\"levantarEmbed\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "bc1238e4-801a-4f9e-b921-68e0a4ef1089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11 ContributorsComo el Sol 2011 Lyrics\\n\\nYeah, hell yeah\\nWell, All Right!\\nWell, All Right!\\nBrillando hasta la E de \"Horizonte\" (Yeah, ahá)\\n\\nMe siento el progenitor de una gran prole\\nEl profesor loco, el preferido del cole\\nMe siento como aquel profeta multitudinario\\nEl propulsor de este flow extra planetario\\nPero el mensaje que te traje no lo temas\\nRespeta a los demás pero a ti al que más (¡Eh!)\\nA mí al que más, llevo brillando eras\\nIluminando a las demás esferas\\nEn sus posibles aunque pobres atmósferas mi rap es un gas\\nMezclando en el oxígeno ritmos y rimas\\nEstos pequeños seres viven mejor\\nLlovió la inteligencia, llovió la sensibilidad\\nY vieron nacer al amor (¡Uh!), y vieron reír al humor (¡Uh!)\\nLlovieron los conceptos, verbos de mi verso creador\\nMi estilo es como caminar por un vergel\\nSe acumula, converge la belleza en este eje\\nHey, en este eje\\nSee Kase.O LiveGet tickets as low as $27You might also like\\nMi estilo es como el sol\\nNada alrededor de mi costado\\nNada alrededor de mi costado\\n'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[\"Kase.O\"][:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f29391c-918d-401b-8e75-ea9b981df515",
   "metadata": {},
   "source": [
    "We are going to clean the texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "a5bde396-6df2-4895-b000-15833c5a2c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # initial processing\n",
    "    text = text.lower()  # lowercase\n",
    "    text = re.sub(r'\\d+', '', text)  # remove numbers\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation)) # remove punctuation\n",
    "\n",
    "    # remove song initial message\n",
    "    text = re.sub(r'contributors.+\\n', '', text)\n",
    "    \n",
    "    # Remove special characters\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "\n",
    "    # remove Genius messages\n",
    "    text = re.sub(\"embed\", '', text)\n",
    "    text = re.sub(r'see\\wliveget tickets as low as', '', text)\n",
    "    text = re.sub(\"you might also like\", '', text)\n",
    "\n",
    "    # remove extra spaces\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "92277ec1-16aa-4ae0-9f41-0ae8fecede45",
   "metadata": {},
   "outputs": [],
   "source": [
    "for artist_name in artist_names:\n",
    "    texts[artist_name] = clean_text(texts[artist_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "ae8eda6a-5a5b-4fb0-ae71-9b440d84ff6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yeah hell yeah well all right well all right brillando hasta la e de horizonte yeah ahá me siento el progenitor de una gran prole el profesor loco el preferido del cole me siento como aquel profeta multitudinario el propulsor de este flow extra planetario pero el mensaje que te traje no lo temas respeta a los demás pero a ti al que más eh a mí al que más llevo brillando eras iluminando a las demás esferas en sus posibles aunque pobres atmósferas mi rap es un gas mezclando en el oxígeno ritmos y rimas estos pequeños seres viven mejor llovió la inteligencia llovió la sensibilidad y vieron nacer al amor uh y vieron reír al humor uh llovieron los conceptos verbos de mi verso creador mi estilo es como caminar por un vergel se acumula converge la belleza en este eje hey en este eje see kaseo liveget tickets as low as mi estilo es como el sol nada alrededor de mi costado nada alrededor de mi costado mi estilo es como el sol fuera de control solo soltero y solitario como el sol nada alrededor '"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[\"Kase.O\"][:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1eb5a5b-4f78-4d7f-99c3-7c26f42e805a",
   "metadata": {},
   "source": [
    "Now we will vectorize the words into tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "8e78747c-7417-403f-bc41-f39747d3e8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/antonio/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/antonio/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['yeah',\n",
       "  'hell',\n",
       "  'yeah',\n",
       "  'well',\n",
       "  'all',\n",
       "  'right',\n",
       "  'well',\n",
       "  'all',\n",
       "  'right',\n",
       "  'brillando']]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "batch_size = 10\n",
    "\n",
    "corpus = {}\n",
    "\n",
    "for name in artist_names:\n",
    "    tokens = word_tokenize(texts[name])\n",
    "    corpus[name] = [tokens[i:i + batch_size] for i in range(0, len(tokens), batch_size)]\n",
    "\n",
    "corpus[\"Kase.O\"][:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "7e44f488-5f1e-4f42-9ca0-1da1b1d5ec3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/antonio/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['yeah', 'hell', 'yeah', 'well', 'right', 'well', 'right', 'brillando'],\n",
       " ['horizonte', 'yeah', 'ahá', 'siento'],\n",
       " ['progenitor', 'gran', 'prole', 'profesor', 'loco', 'preferido']]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words(['english', 'spanish']))\n",
    "\n",
    "filtered_corpus = {}\n",
    "\n",
    "for name in artist_names:\n",
    "    filtered_corpus[name] = [[word for word in doc if word not in stop_words] for doc in corpus[name]]\n",
    "\n",
    "filtered_corpus[\"Kase.O\"][:3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rap",
   "language": "python",
   "name": "rap"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
